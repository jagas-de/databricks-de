{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdc63eff-00f6-435e-bd6a-8f820be44694",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "use catalog asgmnt_test_catlg;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55cfeec4-1cc0-4108-b3d1-cf22995a0eb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "create schema if not exists bronze managed location \n",
    "'abfss://assignments@westeudestorage.dfs.core.windows.net/bronze';\n",
    "create schema if not exists silver managed location\n",
    "'abfss://assignments@westeudestorage.dfs.core.windows.net/silver';\n",
    "create schema if not exists gold managed location\n",
    "'abfss://assignments@westeudestorage.dfs.core.windows.net/gold';\n",
    "\n",
    "create schema if not exists etl_meta managed location\n",
    "'abfss://assignments@westeudestorage.dfs.core.windows.net/etl_meta';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f57fb1c-5a91-461d-aa58-06ef72009a51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, current_timestamp\n",
    "input_path = \"abfss://assignments@westeudestorage.dfs.core.windows.net/input/coil_input.csv\"\n",
    "archive_path = \"abfss://assignments@westeudestorage.dfs.core.windows.net/archive\"\n",
    "catalog_nm = \"asgmnt_test_catlg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b78b796a-31aa-4d21-a3b1-7859337ab157",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# drop table if exists asgmnt_test_catlg.bronze.coil_raw;\n",
    "# drop table if exists asgmnt_test_catlg.silver.coil_stg;\n",
    "# drop table if exists asgmnt_test_catlg.silver.coil_invalid_stg;\n",
    "# drop table if exists asgmnt_test_catlg.gold.coil_summary;\n",
    "# drop table if exists asgmnt_test_catlg.etl_meta.audit_table;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66d7b3b1-94f9-4d45-9965-b055ac7efd6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql.functions import col, count, avg, max, sum, expr, to_date,current_timestamp,lit\n",
    "\n",
    "\n",
    "def log_audit_entry(status, message):\n",
    "    run_timestamp = datetime.now()\n",
    "    batch_id = \"batch_id_\" + str(datetime.now())\n",
    "    audit_entry = [(batch_id, run_timestamp, status, message)]\n",
    "    print(audit_entry)\n",
    "    audit_df = spark.createDataFrame(audit_entry, [\"batch_id\", \"run_timestamp\", \"status\", \"message\"])\n",
    "    audit_df.write.mode('overwrite').saveAsTable(f\"{catalog_nm}.etl_meta.audit_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "679aedcd-3a72-4d5b-9163-288efa5ac8cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load input file into raw table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0335083c-032f-4bc9-a68f-a2a6fee6139d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    if dbutils.fs.ls(input_path):\n",
    "        input_df = spark.read.format(\"csv\").option(\"header\", \"true\")\\\n",
    "            .option(\"inferSchema\", \"true\")\\\n",
    "            .load(f\"{input_path}\")\\\n",
    "            .withColumn('insert_date', current_timestamp())\n",
    "        input_df.write.mode('append').saveAsTable(f'{catalog_nm}.bronze.coil_raw') \n",
    "\n",
    "        # Move files to archive folder\n",
    "        dbutils.fs.mv(input_path, archive_path, True)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"The specified path {input_path} does not exist.\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    log_audit_entry(\"FAILED\", \"Pipeline execution failed to ingest data into raw table.\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7cd2874-51e6-4dc7-b536-5ce173f5bc83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Inspect the data and load valid records into the Silver table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f7da577-01f7-4826-97b7-9cdc11e5d2e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# audit_df = spark.read.table(\"config.audit_table\")\n",
    "# audit_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93b12b95-e54c-4e36-98bb-a9a06d8da673",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+--------------------+\n|            batch_id|       run_timestamp| status|             message|\n+--------------------+--------------------+-------+--------------------+\n|batch_id_2025-01-...|2025-01-21 11:55:...|SUCCESS|The Pipeline is e...|\n+--------------------+--------------------+-------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "if spark._jsparkSession.catalog().tableExists(f\"{catalog_nm}.etl_meta.audit_table\"):\n",
    "    audit_df = spark.read.table(f\"{catalog_nm}.etl_meta.audit_table\")\n",
    "    last_run_timestamp = audit_df.filter(col(\"status\") == \"SUCCESS\").agg({\"run_timestamp\": \"max\"}).collect()[0][0]\n",
    "    audit_df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e457a706-df87-4536-acde-ef9d674d6e24",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load to the silver table"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    raw_df = spark.read.table('bronze.coil_raw')\n",
    "    if last_run_timestamp is not None:\n",
    "       raw_df = raw_df .filter(col('insert_date') > last_run_timestamp)\n",
    "    cleaned_df = raw_df.filter((col(\"coil_id\").isNotNull()) &\n",
    "                                (col(\"production_date\").isNotNull()) &\n",
    "                                (col(\"material_type\").isNotNull()) &\n",
    "                                 ((col(\"weight\").isNotNull())|(col(\"weight\")>0)) &\n",
    "                                 (col(\"thickness\").isNotNull())).distinct()\n",
    "                            \n",
    "\n",
    "    invalid_df = raw_df.filter((col(\"coil_id\").isNull()) |\n",
    "                                (col(\"production_date\").isNull()) |\n",
    "                                (col(\"material_type\").isNull())|\n",
    "                                (col(\"weight\").isNull())| (col(\"weight\")<=0) |\n",
    "                                col(\"thickness\").isNull())\n",
    "    cleaned_df.write.mode('append').saveAsTable('silver.coil_stg')\n",
    "    invalid_df.write.mode('append').saveAsTable('silver.coil_invalid_stg')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    log_audit_entry(\"FAILED\", \"Pipeline execution failed to load silver table.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "743d7091-a855-49f1-af74-948dc138f63c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create a summary table to capture the quality of manufacturing products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eafc825a-45dc-4fd1-8d38-d0bf7053854b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_id_2025-01-21 11:57:11.444512', datetime.datetime(2025, 1, 21, 11, 57, 11, 444505), 'SUCCESS', 'The Pipeline is executed successfully.')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Handle None for last_run_timestamp\n",
    "if last_run_timestamp is None:\n",
    "    last_run_timestamp = \"1990-01-01\"\n",
    "\n",
    "try:\n",
    "    last_run_timestamp = to_timestamp(lit(last_run_timestamp))\n",
    "\n",
    "    # Filter the DataFrame and perform aggregations\n",
    "    output_df = (\n",
    "        spark.table(\"silver.coil_stg\")\n",
    "        .filter(\n",
    "            (col(\"insert_date\") > last_run_timestamp)\n",
    "            & (col(\"weight\") > 1000)\n",
    "            & (col(\"thickness\") >= 1.0)\n",
    "        )\n",
    "        .groupBy(\"material_type\", \"production_date\")\n",
    "        .agg(\n",
    "            count(\"coil_id\").alias(\"total_coils\"),\n",
    "            avg(\"weight\").alias(\"avg_weight\"),\n",
    "            avg(\"thickness\").alias(\"avg_thickness\"),\n",
    "            max(\"line_speed\").alias(\"max_line_speed\"),\n",
    "            sum(\"defects\").alias(\"total_defects\"),\n",
    "            (sum(\"defects\") / count(\"coil_id\") * 100).alias(\"defect_rate\"),\n",
    "        )\n",
    "    )\n",
    "    output_df.createOrReplaceTempView(\"output_df_temp\")\n",
    "\n",
    "    if spark._jsparkSession.catalog().tableExists(f\"{catalog_nm}.default.audit_table\"):\n",
    "        merge_query = \"\"\"\n",
    "   MERGE INTO asgmnt_test_catlg.gold.coil_summary AS target\n",
    "   USING output_df_temp AS source\n",
    "    ON target.production_date = source.production_date AND target.material_type = source.material_type\n",
    "   WHEN MATCHED THEN\n",
    "    UPDATE SET\n",
    "    target.total_coils = source.total_coils,\n",
    "    target.avg_weight = source.avg_weight,\n",
    "    target.avg_thickness = source.avg_thickness,\n",
    "    target.max_line_speed = source.max_line_speed,\n",
    "    target.total_defects = source.total_defects,\n",
    "    target.defect_rate = source.defect_rate\n",
    "   WHEN NOT MATCHED THEN\n",
    "    INSERT (material_type, production_date, total_coils, avg_weight, avg_thickness, max_line_speed, total_defects, defect_rate)\n",
    "   VALUES (source.material_type, source.production_date, source.total_coils, source.avg_weight, source.avg_thickness, source.max_line_speed, source.total_defects, source.defect_rate)\n",
    "    \"\"\"\n",
    "        spark.sql(merge_query)\n",
    "    else:\n",
    "        output_df.write.mode(\"overwrite\").saveAsTable(\n",
    "            \"asgmnt_test_catlg.gold.coil_summary\"\n",
    "        )\n",
    "except exception as e:\n",
    "    log_audit_entry(\"FAILED\", \"Pipeline execution failed to load silver table.\")\n",
    "    dbutils.notebook.exit(1)\n",
    "\n",
    "\n",
    "log_audit_entry(\"SUCCESS\", \"The Pipeline is executed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5f88d85-aa0e-4403-bbaa-6d610340890b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>material_type</th><th>production_date</th><th>total_coils</th><th>avg_weight</th><th>avg_thickness</th><th>max_line_speed</th><th>total_defects</th><th>defect_rate</th></tr></thead><tbody><tr><td>Aluminum</td><td>2024-08-12</td><td>1</td><td>1500.0</td><td>1.1</td><td>195</td><td>1</td><td>100.0</td></tr><tr><td>Steel</td><td>2024-08-12</td><td>2</td><td>1150.0</td><td>1.25</td><td>220</td><td>5</td><td>250.0</td></tr><tr><td>Aluminum</td><td>2024-08-13</td><td>1</td><td>1300.0</td><td>1.4</td><td>210</td><td>0</td><td>0.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Aluminum",
         "2024-08-12",
         1,
         1500.0,
         1.1,
         195,
         1,
         100.0
        ],
        [
         "Steel",
         "2024-08-12",
         2,
         1150.0,
         1.25,
         220,
         5,
         250.0
        ],
        [
         "Aluminum",
         "2024-08-13",
         1,
         1300.0,
         1.4,
         210,
         0,
         0.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 362
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "material_type",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__detected_date_formats\":\"d-M-yyyy\"}",
         "name": "production_date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "total_coils",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "avg_weight",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "avg_thickness",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "max_line_speed",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "total_defects",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "defect_rate",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from asgmnt_test_catlg.gold.coil_summary;\n",
    "select * from asgmnt_test_catlg.etl_meta.audit_table;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f811ed0-cb46-43a5-a92c-4a8c50fb253c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cdf3c08-282d-47b4-8a34-055985f0579a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "GRANT ALL PRIVILEGES ON SCHEMA asgmnt_test_catlg.bronze TO developer_grp;\n",
    "GRANT ALL PRIVILEGES ON SCHEMA asgmnt_test_catlg.silver TO developer_grp;\n",
    "GRANT ALL PRIVILEGES ON SCHEMA asgmnt_test_catlg.gold TO developer_grp;\n",
    "\n",
    "GRANT SELECT ON SCHEMA asgmnt_test_catlg.bronze TO support_L2_grp;\n",
    "GRANT SELECT ON SCHEMA asgmnt_test_catlg.silver TO support_L2_grp;\n",
    "GRANT SELECT ON SCHEMA asgmnt_test_catlg.gold TO support_L2_grp;\n",
    "\n",
    "GRANT SELECT ON TABLE asgmnt_test_catlg.gold.coil_summary TO analyst_grp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44d6b3b5-c32f-490d-8cbf-276101c14f65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "grant All previliges on schema asgmnt_test_catlg.bronze to developer_grp;\n",
    "grant All previliges on schema asgmnt_test_catlg.silver to developer_grp;\n",
    "grant All previliges on schema asgmnt_test_catlg.gold to developer_grp;\n",
    "\n",
    "grant select on table asgmnt_test_catlg.bronze to support_L2_grp;\n",
    "grant select on table asgmnt_test_catlg.silver to support_L2_grp;\n",
    "grant select on table asgmnt_test_catlg.gold to support_L2_grp;\n",
    "\n",
    "grant select on table asgmnt_test_catlg.glod.coil_summary to analyst_grp;\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7224253974346817,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "de-task",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}